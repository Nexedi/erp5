<?xml version="1.0"?>
<ZopeData>
  <record id="1" aka="AAAAAAAAAAE=">
    <pickle>
      <global name="File" module="OFS.Image"/>
    </pickle>
    <pickle>
      <dictionary>
        <item>
            <key> <string>_Cacheable__manager_id</string> </key>
            <value> <string>http_cache</string> </value>
        </item>
        <item>
            <key> <string>_EtagSupport__etag</string> </key>
            <value> <string>ts21897136.51</string> </value>
        </item>
        <item>
            <key> <string>__name__</string> </key>
            <value> <string>python.js</string> </value>
        </item>
        <item>
            <key> <string>content_type</string> </key>
            <value> <string>application/javascript</string> </value>
        </item>
        <item>
            <key> <string>data</string> </key>
            <value> <string encoding="cdata"><![CDATA[

// CodeMirror, copyright (c) by Marijn Haverbeke and others\n
// Distributed under an MIT license: http://codemirror.net/LICENSE\n
\n
(function(mod) {\n
  if (typeof exports == "object" && typeof module == "object") // CommonJS\n
    mod(require("../../lib/codemirror"));\n
  else if (typeof define == "function" && define.amd) // AMD\n
    define(["../../lib/codemirror"], mod);\n
  else // Plain browser env\n
    mod(CodeMirror);\n
})(function(CodeMirror) {\n
  "use strict";\n
\n
  function wordRegexp(words) {\n
    return new RegExp("^((" + words.join(")|(") + "))\\\\b");\n
  }\n
\n
  var wordOperators = wordRegexp(["and", "or", "not", "is"]);\n
  var commonKeywords = ["as", "assert", "break", "class", "continue",\n
                        "def", "del", "elif", "else", "except", "finally",\n
                        "for", "from", "global", "if", "import",\n
                        "lambda", "pass", "raise", "return",\n
                        "try", "while", "with", "yield", "in"];\n
  var commonBuiltins = ["abs", "all", "any", "bin", "bool", "bytearray", "callable", "chr",\n
                        "classmethod", "compile", "complex", "delattr", "dict", "dir", "divmod",\n
                        "enumerate", "eval", "filter", "float", "format", "frozenset",\n
                        "getattr", "globals", "hasattr", "hash", "help", "hex", "id",\n
                        "input", "int", "isinstance", "issubclass", "iter", "len",\n
                        "list", "locals", "map", "max", "memoryview", "min", "next",\n
                        "object", "oct", "open", "ord", "pow", "property", "range",\n
                        "repr", "reversed", "round", "set", "setattr", "slice",\n
                        "sorted", "staticmethod", "str", "sum", "super", "tuple",\n
                        "type", "vars", "zip", "__import__", "NotImplemented",\n
                        "Ellipsis", "__debug__"];\n
  var py2 = {builtins: ["apply", "basestring", "buffer", "cmp", "coerce", "execfile",\n
                        "file", "intern", "long", "raw_input", "reduce", "reload",\n
                        "unichr", "unicode", "xrange", "False", "True", "None"],\n
             keywords: ["exec", "print"]};\n
  var py3 = {builtins: ["ascii", "bytes", "exec", "print"],\n
             keywords: ["nonlocal", "False", "True", "None"]};\n
\n
  CodeMirror.registerHelper("hintWords", "python", commonKeywords.concat(commonBuiltins));\n
\n
  function top(state) {\n
    return state.scopes[state.scopes.length - 1];\n
  }\n
\n
  CodeMirror.defineMode("python", function(conf, parserConf) {\n
    var ERRORCLASS = "error";\n
\n
    var singleDelimiters = parserConf.singleDelimiters || new RegExp("^[\\\\(\\\\)\\\\[\\\\]\\\\{\\\\}@,:`=;\\\\.]");\n
    var doubleOperators = parserConf.doubleOperators || new RegExp("^((==)|(!=)|(<=)|(>=)|(<>)|(<<)|(>>)|(//)|(\\\\*\\\\*))");\n
    var doubleDelimiters = parserConf.doubleDelimiters || new RegExp("^((\\\\+=)|(\\\\-=)|(\\\\*=)|(%=)|(/=)|(&=)|(\\\\|=)|(\\\\^=))");\n
    var tripleDelimiters = parserConf.tripleDelimiters || new RegExp("^((//=)|(>>=)|(<<=)|(\\\\*\\\\*=))");\n
\n
    if (parserConf.version && parseInt(parserConf.version, 10) == 3){\n
        // since http://legacy.python.org/dev/peps/pep-0465/ @ is also an operator\n
        var singleOperators = parserConf.singleOperators || new RegExp("^[\\\\+\\\\-\\\\*/%&|\\\\^~<>!@]");\n
        var identifiers = parserConf.identifiers|| new RegExp("^[_A-Za-z\\u00A1-\\uFFFF][_A-Za-z0-9\\u00A1-\\uFFFF]*");\n
    } else {\n
        var singleOperators = parserConf.singleOperators || new RegExp("^[\\\\+\\\\-\\\\*/%&|\\\\^~<>!]");\n
        var identifiers = parserConf.identifiers|| new RegExp("^[_A-Za-z][_A-Za-z0-9]*");\n
    }\n
\n
    var hangingIndent = parserConf.hangingIndent || conf.indentUnit;\n
\n
    var myKeywords = commonKeywords, myBuiltins = commonBuiltins;\n
    if(parserConf.extra_keywords != undefined){\n
      myKeywords = myKeywords.concat(parserConf.extra_keywords);\n
    }\n
    if(parserConf.extra_builtins != undefined){\n
      myBuiltins = myBuiltins.concat(parserConf.extra_builtins);\n
    }\n
    if (parserConf.version && parseInt(parserConf.version, 10) == 3) {\n
      myKeywords = myKeywords.concat(py3.keywords);\n
      myBuiltins = myBuiltins.concat(py3.builtins);\n
      var stringPrefixes = new RegExp("^(([rb]|(br))?(\'{3}|\\"{3}|[\'\\"]))", "i");\n
    } else {\n
      myKeywords = myKeywords.concat(py2.keywords);\n
      myBuiltins = myBuiltins.concat(py2.builtins);\n
      var stringPrefixes = new RegExp("^(([rub]|(ur)|(br))?(\'{3}|\\"{3}|[\'\\"]))", "i");\n
    }\n
    var keywords = wordRegexp(myKeywords);\n
    var builtins = wordRegexp(myBuiltins);\n
\n
    // tokenizers\n
    function tokenBase(stream, state) {\n
      // Handle scope changes\n
      if (stream.sol() && top(state).type == "py") {\n
        var scopeOffset = top(state).offset;\n
        if (stream.eatSpace()) {\n
          var lineOffset = stream.indentation();\n
          if (lineOffset > scopeOffset)\n
            pushScope(stream, state, "py");\n
          else if (lineOffset < scopeOffset && dedent(stream, state))\n
            state.errorToken = true;\n
          return null;\n
        } else {\n
          var style = tokenBaseInner(stream, state);\n
          if (scopeOffset > 0 && dedent(stream, state))\n
            style += " " + ERRORCLASS;\n
          return style;\n
        }\n
      }\n
      return tokenBaseInner(stream, state);\n
    }\n
\n
    function tokenBaseInner(stream, state) {\n
      if (stream.eatSpace()) return null;\n
\n
      var ch = stream.peek();\n
\n
      // Handle Comments\n
      if (ch == "#") {\n
        stream.skipToEnd();\n
        return "comment";\n
      }\n
\n
      // Handle Number Literals\n
      if (stream.match(/^[0-9\\.]/, false)) {\n
        var floatLiteral = false;\n
        // Floats\n
        if (stream.match(/^\\d*\\.\\d+(e[\\+\\-]?\\d+)?/i)) { floatLiteral = true; }\n
        if (stream.match(/^\\d+\\.\\d*/)) { floatLiteral = true; }\n
        if (stream.match(/^\\.\\d+/)) { floatLiteral = true; }\n
        if (floatLiteral) {\n
          // Float literals may be "imaginary"\n
          stream.eat(/J/i);\n
          return "number";\n
        }\n
        // Integers\n
        var intLiteral = false;\n
        // Hex\n
        if (stream.match(/^0x[0-9a-f]+/i)) intLiteral = true;\n
        // Binary\n
        if (stream.match(/^0b[01]+/i)) intLiteral = true;\n
        // Octal\n
        if (stream.match(/^0o[0-7]+/i)) intLiteral = true;\n
        // Decimal\n
        if (stream.match(/^[1-9]\\d*(e[\\+\\-]?\\d+)?/)) {\n
          // Decimal literals may be "imaginary"\n
          stream.eat(/J/i);\n
          // TODO - Can you have imaginary longs?\n
          intLiteral = true;\n
        }\n
        // Zero by itself with no other piece of number.\n
        if (stream.match(/^0(?![\\dx])/i)) intLiteral = true;\n
        if (intLiteral) {\n
          // Integer literals may be "long"\n
          stream.eat(/L/i);\n
          return "number";\n
        }\n
      }\n
\n
      // Handle Strings\n
      if (stream.match(stringPrefixes)) {\n
        state.tokenize = tokenStringFactory(stream.current());\n
        return state.tokenize(stream, state);\n
      }\n
\n
      // Handle operators and Delimiters\n
      if (stream.match(tripleDelimiters) || stream.match(doubleDelimiters))\n
        return null;\n
\n
      if (stream.match(doubleOperators)\n
          || stream.match(singleOperators)\n
          || stream.match(wordOperators))\n
        return "operator";\n
\n
      if (stream.match(singleDelimiters))\n
        return null;\n
\n
      if (stream.match(keywords))\n
        return "keyword";\n
\n
      if (stream.match(builtins))\n
        return "builtin";\n
\n
      if (stream.match(/^(self|cls)\\b/))\n
        return "variable-2";\n
\n
      if (stream.match(identifiers)) {\n
        if (state.lastToken == "def" || state.lastToken == "class")\n
          return "def";\n
        return "variable";\n
      }\n
\n
      // Handle non-detected items\n
      stream.next();\n
      return ERRORCLASS;\n
    }\n
\n
    function tokenStringFactory(delimiter) {\n
      while ("rub".indexOf(delimiter.charAt(0).toLowerCase()) >= 0)\n
        delimiter = delimiter.substr(1);\n
\n
      var singleline = delimiter.length == 1;\n
      var OUTCLASS = "string";\n
\n
      function tokenString(stream, state) {\n
        while (!stream.eol()) {\n
          stream.eatWhile(/[^\'"\\\\]/);\n
          if (stream.eat("\\\\")) {\n
            stream.next();\n
            if (singleline && stream.eol())\n
              return OUTCLASS;\n
          } else if (stream.match(delimiter)) {\n
            state.tokenize = tokenBase;\n
            return OUTCLASS;\n
          } else {\n
            stream.eat(/[\'"]/);\n
          }\n
        }\n
        if (singleline) {\n
          if (parserConf.singleLineStringErrors)\n
            return ERRORCLASS;\n
          else\n
            state.tokenize = tokenBase;\n
        }\n
        return OUTCLASS;\n
      }\n
      tokenString.isString = true;\n
      return tokenString;\n
    }\n
\n
    function pushScope(stream, state, type) {\n
      var offset = 0, align = null;\n
      if (type == "py") {\n
        while (top(state).type != "py")\n
          state.scopes.pop();\n
      }\n
      offset = top(state).offset + (type == "py" ? conf.indentUnit : hangingIndent);\n
      if (type != "py" && !stream.match(/^(\\s|#.*)*$/, false))\n
        align = stream.column() + 1;\n
      state.scopes.push({offset: offset, type: type, align: align});\n
    }\n
\n
    function dedent(stream, state) {\n
      var indented = stream.indentation();\n
      while (top(state).offset > indented) {\n
        if (top(state).type != "py") return true;\n
        state.scopes.pop();\n
      }\n
      return top(state).offset != indented;\n
    }\n
\n
    function tokenLexer(stream, state) {\n
      var style = state.tokenize(stream, state);\n
      var current = stream.current();\n
\n
      // Handle \'.\' connected identifiers\n
      if (current == ".") {\n
        style = stream.match(identifiers, false) ? null : ERRORCLASS;\n
        if (style == null && state.lastStyle == "meta") {\n
          // Apply \'meta\' style to \'.\' connected identifiers when\n
          // appropriate.\n
          style = "meta";\n
        }\n
        return style;\n
      }\n
\n
      // Handle decorators\n
      if (current == "@"){\n
        if(parserConf.version && parseInt(parserConf.version, 10) == 3){\n
            return stream.match(identifiers, false) ? "meta" : "operator";\n
        } else {\n
            return stream.match(identifiers, false) ? "meta" : ERRORCLASS;\n
        }\n
      }\n
\n
      if ((style == "variable" || style == "builtin")\n
          && state.lastStyle == "meta")\n
        style = "meta";\n
\n
      // Handle scope changes.\n
      if (current == "pass" || current == "return")\n
        state.dedent += 1;\n
\n
      if (current == "lambda") state.lambda = true;\n
      if (current == ":" && !state.lambda && top(state).type == "py")\n
        pushScope(stream, state, "py");\n
\n
      var delimiter_index = current.length == 1 ? "[({".indexOf(current) : -1;\n
      if (delimiter_index != -1)\n
        pushScope(stream, state, "])}".slice(delimiter_index, delimiter_index+1));\n
\n
      delimiter_index = "])}".indexOf(current);\n
      if (delimiter_index != -1) {\n
        if (top(state).type == current) state.scopes.pop();\n
        else return ERRORCLASS;\n
      }\n
      if (state.dedent > 0 && stream.eol() && top(state).type == "py") {\n
        if (state.scopes.length > 1) state.scopes.pop();\n
        state.dedent -= 1;\n
      }\n
\n
      return style;\n
    }\n
\n
    var external = {\n
      startState: function(basecolumn) {\n
        return {\n
          tokenize: tokenBase,\n
          scopes: [{offset: basecolumn || 0, type: "py", align: null}],\n
          lastStyle: null,\n
          lastToken: null,\n
          lambda: false,\n
          dedent: 0\n
        };\n
      },\n
\n
      token: function(stream, state) {\n
        var addErr = state.errorToken;\n
        if (addErr) state.errorToken = false;\n
        var style = tokenLexer(stream, state);\n
\n
        state.lastStyle = style;\n
\n
        var current = stream.current();\n
        if (current && style)\n
          state.lastToken = current;\n
\n
        if (stream.eol() && state.lambda)\n
          state.lambda = false;\n
        return addErr ? style + " " + ERRORCLASS : style;\n
      },\n
\n
      indent: function(state, textAfter) {\n
        if (state.tokenize != tokenBase)\n
          return state.tokenize.isString ? CodeMirror.Pass : 0;\n
\n
        var scope = top(state);\n
        var closing = textAfter && textAfter.charAt(0) == scope.type;\n
        if (scope.align != null)\n
          return scope.align - (closing ? 1 : 0);\n
        else if (closing && state.scopes.length > 1)\n
          return state.scopes[state.scopes.length - 2].offset;\n
        else\n
          return scope.offset;\n
      },\n
\n
      lineComment: "#",\n
      fold: "indent"\n
    };\n
    return external;\n
  });\n
\n
  CodeMirror.defineMIME("text/x-python", "python");\n
\n
  var words = function(str) { return str.split(" "); };\n
\n
  CodeMirror.defineMIME("text/x-cython", {\n
    name: "python",\n
    extra_keywords: words("by cdef cimport cpdef ctypedef enum except"+\n
                          "extern gil include nogil property public"+\n
                          "readonly struct union DEF IF ELIF ELSE")\n
  });\n
\n
});\n


]]></string> </value>
        </item>
        <item>
            <key> <string>precondition</string> </key>
            <value> <string></string> </value>
        </item>
        <item>
            <key> <string>size</string> </key>
            <value> <int>12869</int> </value>
        </item>
        <item>
            <key> <string>title</string> </key>
            <value> <string></string> </value>
        </item>
      </dictionary>
    </pickle>
  </record>
</ZopeData>
