<?xml version="1.0"?>
<ZopeData>
  <record id="1" aka="AAAAAAAAAAE=">
    <pickle>
      <global name="File" module="OFS.Image"/>
    </pickle>
    <pickle>
      <dictionary>
        <item>
            <key> <string>_Cacheable__manager_id</string> </key>
            <value> <string>http_cache</string> </value>
        </item>
        <item>
            <key> <string>_EtagSupport__etag</string> </key>
            <value> <string>ts60604376.78</string> </value>
        </item>
        <item>
            <key> <string>__name__</string> </key>
            <value> <string>crystal.js</string> </value>
        </item>
        <item>
            <key> <string>content_type</string> </key>
            <value> <string>application/javascript</string> </value>
        </item>
        <item>
            <key> <string>data</string> </key>
            <value> <string encoding="cdata"><![CDATA[

// CodeMirror, copyright (c) by Marijn Haverbeke and others\n
// Distributed under an MIT license: http://codemirror.net/LICENSE\n
\n
(function(mod) {\n
  if (typeof exports == "object" && typeof module == "object") // CommonJS\n
    mod(require("../../lib/codemirror"));\n
  else if (typeof define == "function" && define.amd) // AMD\n
    define(["../../lib/codemirror"], mod);\n
  else // Plain browser env\n
    mod(CodeMirror);\n
})(function(CodeMirror) {\n
  "use strict";\n
\n
  CodeMirror.defineMode("crystal", function(config) {\n
    function wordRegExp(words, end) {\n
      return new RegExp((end ? "" : "^") + "(?:" + words.join("|") + ")" + (end ? "$" : "\\\\b"));\n
    }\n
\n
    function chain(tokenize, stream, state) {\n
      state.tokenize.push(tokenize);\n
      return tokenize(stream, state);\n
    }\n
\n
    var operators = /^(?:[-+/%|&^]|\\*\\*?|[<>]{2})/;\n
    var conditionalOperators = /^(?:[=!]~|===|<=>|[<>=!]=?|[|&]{2}|~)/;\n
    var indexingOperators = /^(?:\\[\\][?=]?)/;\n
    var anotherOperators = /^(?:\\.(?:\\.{2})?|->|[?:])/;\n
    var idents = /^[a-z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\n
    var types = /^[A-Z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\n
    var keywords = wordRegExp([\n
      "abstract", "alias", "as", "asm", "begin", "break", "case", "class", "def", "do",\n
      "else", "elsif", "end", "ensure", "enum", "extend", "for", "fun", "if", "ifdef",\n
      "include", "instance_sizeof", "lib", "macro", "module", "next", "of", "out", "pointerof",\n
      "private", "protected", "rescue", "return", "require", "sizeof", "struct",\n
      "super", "then", "type", "typeof", "union", "unless", "until", "when", "while", "with",\n
      "yield", "__DIR__", "__FILE__", "__LINE__"\n
    ]);\n
    var atomWords = wordRegExp(["true", "false", "nil", "self"]);\n
    var indentKeywordsArray = [\n
      "def", "fun", "macro",\n
      "class", "module", "struct", "lib", "enum", "union",\n
      "if", "unless", "case", "while", "until", "begin", "then",\n
      "do",\n
      "for", "ifdef"\n
    ];\n
    var indentKeywords = wordRegExp(indentKeywordsArray);\n
    var dedentKeywordsArray = [\n
      "end",\n
      "else", "elsif",\n
      "rescue", "ensure"\n
    ];\n
    var dedentKeywords = wordRegExp(dedentKeywordsArray);\n
    var dedentPunctualsArray = ["\\\\)", "\\\\}", "\\\\]"];\n
    var dedentPunctuals = new RegExp("^(?:" + dedentPunctualsArray.join("|") + ")$");\n
    var nextTokenizer = {\n
      "def": tokenFollowIdent, "fun": tokenFollowIdent, "macro": tokenMacroDef,\n
      "class": tokenFollowType, "module": tokenFollowType, "struct": tokenFollowType,\n
      "lib": tokenFollowType, "enum": tokenFollowType, "union": tokenFollowType\n
    };\n
    var matching = {"[": "]", "{": "}", "(": ")", "<": ">"};\n
\n
    function tokenBase(stream, state) {\n
      if (stream.eatSpace()) {\n
        return null;\n
      }\n
\n
      // Macros\n
      if (state.lastToken != "\\\\" && stream.match("{%", false)) {\n
        return chain(tokenMacro("%", "%"), stream, state);\n
      }\n
\n
      if (state.lastToken != "\\\\" && stream.match("{{", false)) {\n
        return chain(tokenMacro("{", "}"), stream, state);\n
      }\n
\n
      // Comments\n
      if (stream.peek() == "#") {\n
        stream.skipToEnd();\n
        return "comment";\n
      }\n
\n
      // Variables and keywords\n
      var matched;\n
      if (stream.match(idents)) {\n
        stream.eat(/[?!]/);\n
\n
        matched = stream.current();\n
        if (stream.eat(":")) {\n
          return "atom";\n
        } else if (state.lastToken == ".") {\n
          return "property";\n
        } else if (keywords.test(matched)) {\n
          if (state.lastToken != "abstract" && indentKeywords.test(matched)) {\n
            if (!(matched == "fun" && state.blocks.indexOf("lib") >= 0)) {\n
              state.blocks.push(matched);\n
              state.currentIndent += 1;\n
            }\n
          } else if (dedentKeywords.test(matched)) {\n
            state.blocks.pop();\n
            state.currentIndent -= 1;\n
          }\n
\n
          if (nextTokenizer.hasOwnProperty(matched)) {\n
            state.tokenize.push(nextTokenizer[matched]);\n
          }\n
\n
          return "keyword";\n
        } else if (atomWords.test(matched)) {\n
          return "atom";\n
        }\n
\n
        return "variable";\n
      }\n
\n
      // Class variables and instance variables\n
      // or attributes\n
      if (stream.eat("@")) {\n
        if (stream.peek() == "[") {\n
          return chain(tokenNest("[", "]", "meta"), stream, state);\n
        }\n
\n
        stream.eat("@");\n
        stream.match(idents) || stream.match(types);\n
        return "variable-2";\n
      }\n
\n
      // Global variables\n
      if (stream.eat("$")) {\n
        stream.eat(/[0-9]+|\\?/) || stream.match(idents) || stream.match(types);\n
        return "variable-3";\n
      }\n
\n
      // Constants and types\n
      if (stream.match(types)) {\n
        return "tag";\n
      }\n
\n
      // Symbols or \':\' operator\n
      if (stream.eat(":")) {\n
        if (stream.eat("\\"")) {\n
          return chain(tokenQuote("\\"", "atom", false), stream, state);\n
        } else if (stream.match(idents) || stream.match(types) ||\n
                   stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators)) {\n
          return "atom";\n
        }\n
        stream.eat(":");\n
        return "operator";\n
      }\n
\n
      // Strings\n
      if (stream.eat("\\"")) {\n
        return chain(tokenQuote("\\"", "string", true), stream, state);\n
      }\n
\n
      // Strings or regexps or macro variables or \'%\' operator\n
      if (stream.peek() == "%") {\n
        var style = "string";\n
        var embed = true;\n
        var delim;\n
\n
        if (stream.match("%r")) {\n
          // Regexps\n
          style = "string-2";\n
          delim = stream.next();\n
        } else if (stream.match("%w")) {\n
          embed = false;\n
          delim = stream.next();\n
        } else {\n
          if(delim = stream.match(/^%([^\\w\\s=])/)) {\n
            delim = delim[1];\n
          } else if (stream.match(/^%[a-zA-Z0-9_\\u009F-\\uFFFF]*/)) {\n
            // Macro variables\n
            return "meta";\n
          } else {\n
            // \'%\' operator\n
            return "operator";\n
          }\n
        }\n
\n
        if (matching.hasOwnProperty(delim)) {\n
          delim = matching[delim];\n
        }\n
        return chain(tokenQuote(delim, style, embed), stream, state);\n
      }\n
\n
      // Characters\n
      if (stream.eat("\'")) {\n
        stream.match(/^(?:[^\']|\\\\(?:[befnrtv0\'"]|[0-7]{3}|u(?:[0-9a-fA-F]{4}|\\{[0-9a-fA-F]{1,6}\\})))/);\n
        stream.eat("\'");\n
        return "atom";\n
      }\n
\n
      // Numbers\n
      if (stream.eat("0")) {\n
        if (stream.eat("x")) {\n
          stream.match(/^[0-9a-fA-F]+/);\n
        } else if (stream.eat("o")) {\n
          stream.match(/^[0-7]+/);\n
        } else if (stream.eat("b")) {\n
          stream.match(/^[01]+/);\n
        }\n
        return "number";\n
      }\n
\n
      if (stream.eat(/\\d/)) {\n
        stream.match(/^\\d*(?:\\.\\d+)?(?:[eE][+-]?\\d+)?/);\n
        return "number";\n
      }\n
\n
      // Operators\n
      if (stream.match(operators)) {\n
        stream.eat("="); // Operators can follow assigin symbol.\n
        return "operator";\n
      }\n
\n
      if (stream.match(conditionalOperators) || stream.match(anotherOperators)) {\n
        return "operator";\n
      }\n
\n
      // Parens and braces\n
      if (matched = stream.match(/[({[]/, false)) {\n
        matched = matched[0];\n
        return chain(tokenNest(matched, matching[matched], null), stream, state);\n
      }\n
\n
      // Escapes\n
      if (stream.eat("\\\\")) {\n
        stream.next();\n
        return "meta";\n
      }\n
\n
      stream.next();\n
      return null;\n
    }\n
\n
    function tokenNest(begin, end, style, started) {\n
      return function (stream, state) {\n
        if (!started && stream.match(begin)) {\n
          state.tokenize[state.tokenize.length - 1] = tokenNest(begin, end, style, true);\n
          state.currentIndent += 1;\n
          return style;\n
        }\n
\n
        var nextStyle = tokenBase(stream, state);\n
        if (stream.current() === end) {\n
          state.tokenize.pop();\n
          state.currentIndent -= 1;\n
          nextStyle = style;\n
        }\n
\n
        return nextStyle;\n
      };\n
    }\n
\n
    function tokenMacro(begin, end, started) {\n
      return function (stream, state) {\n
        if (!started && stream.match("{" + begin)) {\n
          state.currentIndent += 1;\n
          state.tokenize[state.tokenize.length - 1] = tokenMacro(begin, end, true);\n
          return "meta";\n
        }\n
\n
        if (stream.match(end + "}")) {\n
          state.currentIndent -= 1;\n
          state.tokenize.pop();\n
          return "meta";\n
        }\n
\n
        return tokenBase(stream, state);\n
      };\n
    }\n
\n
    function tokenMacroDef(stream, state) {\n
      if (stream.eatSpace()) {\n
        return null;\n
      }\n
\n
      var matched;\n
      if (matched = stream.match(idents)) {\n
        if (matched == "def") {\n
          return "keyword";\n
        }\n
        stream.eat(/[?!]/);\n
      }\n
\n
      state.tokenize.pop();\n
      return "def";\n
    }\n
\n
    function tokenFollowIdent(stream, state) {\n
      if (stream.eatSpace()) {\n
        return null;\n
      }\n
\n
      if (stream.match(idents)) {\n
        stream.eat(/[!?]/);\n
      } else {\n
        stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators);\n
      }\n
      state.tokenize.pop();\n
      return "def";\n
    }\n
\n
    function tokenFollowType(stream, state) {\n
      if (stream.eatSpace()) {\n
        return null;\n
      }\n
\n
      stream.match(types);\n
      state.tokenize.pop();\n
      return "def";\n
    }\n
\n
    function tokenQuote(end, style, embed) {\n
      return function (stream, state) {\n
        var escaped = false;\n
\n
        while (stream.peek()) {\n
          if (!escaped) {\n
            if (stream.match("{%", false)) {\n
              state.tokenize.push(tokenMacro("%", "%"));\n
              return style;\n
            }\n
\n
            if (stream.match("{{", false)) {\n
              state.tokenize.push(tokenMacro("{", "}"));\n
              return style;\n
            }\n
\n
            if (embed && stream.match("#{", false)) {\n
              state.tokenize.push(tokenNest("#{", "}", "meta"));\n
              return style;\n
            }\n
\n
            var ch = stream.next();\n
\n
            if (ch == end) {\n
              state.tokenize.pop();\n
              return style;\n
            }\n
\n
            escaped = ch == "\\\\";\n
          } else {\n
            stream.next();\n
            escaped = false;\n
          }\n
        }\n
\n
        return style;\n
      };\n
    }\n
\n
    return {\n
      startState: function () {\n
        return {\n
          tokenize: [tokenBase],\n
          currentIndent: 0,\n
          lastToken: null,\n
          blocks: []\n
        };\n
      },\n
\n
      token: function (stream, state) {\n
        var style = state.tokenize[state.tokenize.length - 1](stream, state);\n
        var token = stream.current();\n
\n
        if (style && style != "comment") {\n
          state.lastToken = token;\n
        }\n
\n
        return style;\n
      },\n
\n
      indent: function (state, textAfter) {\n
        textAfter = textAfter.replace(/^\\s*(?:\\{%)?\\s*|\\s*(?:%\\})?\\s*$/g, "");\n
\n
        if (dedentKeywords.test(textAfter) || dedentPunctuals.test(textAfter)) {\n
          return config.indentUnit * (state.currentIndent - 1);\n
        }\n
\n
        return config.indentUnit * state.currentIndent;\n
      },\n
\n
      fold: "indent",\n
      electricInput: wordRegExp(dedentPunctualsArray.concat(dedentKeywordsArray), true),\n
      lineComment: \'#\'\n
    };\n
  });\n
\n
  CodeMirror.defineMIME("text/x-crystal", "crystal");\n
});\n


]]></string> </value>
        </item>
        <item>
            <key> <string>precondition</string> </key>
            <value> <string></string> </value>
        </item>
        <item>
            <key> <string>size</string> </key>
            <value> <int>11339</int> </value>
        </item>
        <item>
            <key> <string>title</string> </key>
            <value> <string></string> </value>
        </item>
      </dictionary>
    </pickle>
  </record>
</ZopeData>
