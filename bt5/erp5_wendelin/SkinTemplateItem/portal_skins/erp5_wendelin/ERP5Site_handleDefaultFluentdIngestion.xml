<?xml version="1.0"?>
<ZopeData>
  <record id="1" aka="AAAAAAAAAAE=">
    <pickle>
      <global name="PythonScript" module="Products.PythonScripts.PythonScript"/>
    </pickle>
    <pickle>
      <dictionary>
        <item>
            <key> <string>Script_magic</string> </key>
            <value> <int>3</int> </value>
        </item>
        <item>
            <key> <string>_bind_names</string> </key>
            <value>
              <object>
                <klass>
                  <global name="NameAssignments" module="Shared.DC.Scripts.Bindings"/>
                </klass>
                <tuple/>
                <state>
                  <dictionary>
                    <item>
                        <key> <string>_asgns</string> </key>
                        <value>
                          <dictionary>
                            <item>
                                <key> <string>name_container</string> </key>
                                <value> <string>container</string> </value>
                            </item>
                            <item>
                                <key> <string>name_context</string> </key>
                                <value> <string>context</string> </value>
                            </item>
                            <item>
                                <key> <string>name_m_self</string> </key>
                                <value> <string>script</string> </value>
                            </item>
                            <item>
                                <key> <string>name_subpath</string> </key>
                                <value> <string>traverse_subpath</string> </value>
                            </item>
                          </dictionary>
                        </value>
                    </item>
                  </dictionary>
                </state>
              </object>
            </value>
        </item>
        <item>
            <key> <string>_body</string> </key>
            <value> <string encoding="cdata"><![CDATA[

"""\n
  Example of ingesting data in ERP5 coming from fluentd.\n
  Fluentd sends to us a JSON dictionary using msgpack protocol.\n
  In this implementation we find respective Data Stream and simply\n
  append data there. We save raw JSON dictionary as string.\n
  Ingestion Policy -> Data Supply -> Data Supply Line -> Sensor\n
                                                      -> Data Stream\n
"""\n
from DateTime import DateTime\n
from zExceptions import NotFound\n
from Products.ZSQLCatalog.SQLCatalog import ComplexQuery\n
from Products.ZSQLCatalog.SQLCatalog import Query\n
   \n
\n
now = DateTime()\n
request = context.REQUEST\n
portal_catalog = context.portal_catalog\n
\n
reference = request.get(\'reference\')\n
data_chunk = request.get(\'data_chunk\')\n
\n
if data_chunk is not None and reference is not None:\n
  # here we rely that fluentd will pass to us its tag which we use\n
  # as reference but we can extract it sometimes from sensor data\n
  # it thus depends on sensor and the fluentd topography\n
  query=ComplexQuery(Query(portal_type = \'Data Supply\'),\n
                     Query(reference = reference),\n
                     Query(validation_state = \'validated\'),\n
                     # XXX: enable when final decision made if Data Supply is a\n
                     # Delivery or Supply\n
                     #Query( **{\'delivery.stop_date\':now,  \'range\': \'max\'}),\n
                     #Query( **{\'delivery.start_date\':now,  \'range\': \'min\'}),\n
                     operator="AND")\n
  data_supply = portal_catalog.getResultValue(query=query)\n
\n
  #context.log(data_supply)\n
  # we can have multiple lines for each sensor and we filter out by reference\n
  # XXX: in future we will use Predicates to find already generated\n
  # Data Ingestion (Movements)\n
  if data_supply is not None:\n
    for data_supply_line in data_supply.objectValues():\n
      sensor = data_supply_line.getSourceValue()\n
      if sensor is not None and sensor.getReference() == reference:\n
        # Sensor is defined as destination\n
        data_stream = data_supply_line.getDestinationValue()\n
        break\n
\n
    #context.log(sensor)\n
    #context.log(data_stream)\n
    if data_stream is not None:\n
      pretty_data_chunk_list = []\n
      data_chunk_list = context.unpack(data_chunk)\n
\n
      for data_chunk in data_chunk_list:\n
        pretty_data = str(data_chunk[1])\n
        pretty_data_chunk_list.append(pretty_data)\n
      data = \'\'.join(pretty_data_chunk_list)\n
\n
      # append data\n
      data_stream.appendData(data)\n
\n
      #context.log("Appended %s bytes to %s (%s, %s, %s)"   \n
      #              %(len(data), reference, data_supply, sensor, data_stream))\n
      # XXX: open question -> we do not store the act of ingestion.\n
      # one way is to have a business process for who\'s "ingestion" \n
      # trade_phase / state we generate simulation movements and respective \n
      # objects in data_ingestion_module. We can use same approach and same \n
      # business process for analytics stage (just different trade_state / phase)?\n
      # JP: we should use this approach at a later stage\n
      # this approach can be hooked through interaction workflow on data stream\n
    else:\n
      raise NotFound(\'No data stream configuration found.\')      \n
  else:\n
    raise NotFound(\'No data supply configuration found.\')\n
else:\n
  raise NotFound(\'No data or any configuration not found.\')\n


]]></string> </value>
        </item>
        <item>
            <key> <string>_params</string> </key>
            <value> <string></string> </value>
        </item>
        <item>
            <key> <string>id</string> </key>
            <value> <string>ERP5Site_handleDefaultFluentdIngestion</string> </value>
        </item>
      </dictionary>
    </pickle>
  </record>
</ZopeData>
